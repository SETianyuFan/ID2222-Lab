{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2: Discovery of Frequent Itemsets and Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "You are to solve the first sub-problem: to implement the A-Priori algorithm for finding frequent itemsets with support at least s in a dataset of sales transactions. Remind that support of an itemset is the number of transactions containing the itemset. To test and evaluate your implementation, write a program that uses your A-Priori algorithm implementation to discover frequent itemsets with support at least s in a given dataset of sales transactions.\n",
    "\n",
    "The implementation can be done using any big data processing framework, such as Apache Spark, Apache Flink, or no framework, e.g., in Java, Python, etc.  \n",
    "\n",
    "The optional task for an extra bonus\n",
    "Solve the second sub-problem, i.e., develop and implement an algorithm for generating association rules between frequent itemsets discovered using the A-Priori algorithm in a dataset of sales transactions. The rules must have the support of at least s and confidence of at least c, where s and c are given as input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Introduction\n",
    "* Create function \"apriori\" to create frequent set.\n",
    "* Create function to get associate member by using frequent set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libararies\n",
    "\n",
    "Here are some libraries that I used in the program.\n",
    "* Using \"numpy\" as our data format. \n",
    "* Using \"collections\" to computes and merges the same elements in one list in the function \"LSH\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sets:\n",
    "\n",
    "I used data sets which is given by Assignment2. I transform the data sets into list for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25, 52, 164, 240, 274, 328, 368, 448, 538, 561, 630, 687, 730, 775, 825, 834], [39, 120, 124, 205, 401, 581, 704, 814, 825, 834]]\n"
     ]
    }
   ],
   "source": [
    "# Import sales data\n",
    "dataPath = \"T10I4D100K.dat\"\n",
    "baskets = []\n",
    "\n",
    "f = open(dataPath, 'r')\n",
    "\n",
    "for doc in f:\n",
    "    docStr = doc.rstrip()\n",
    "    item = list(docStr.split(' '))\n",
    "    for i in range(len(item)):\n",
    "        item[i] = int(item[i])\n",
    "    #print(item)\n",
    "    baskets.append(item)\n",
    "\n",
    "print(baskets[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Apriori Augorithm\n",
    "\n",
    "* Function \"getAllItems\": create a list with all characters in baskets.\n",
    "* Function \"getFirstStage\": create a list that only contains frequent character.\n",
    "* Function \"getRelevanItems\": create a list that only contains frequent character sets in each iteration.\n",
    "* Function \"createItems\": create a list that contains next stage items by using relevant items that created by function \"getRelevantItems\".\n",
    "* Function \"getItemsCount\": create a list that save the computation result of the frequency of items for next stage.\n",
    "* Function \"apriori\": use these functions above to get the final results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[25], 13], [[52], 19], [[164], 11], [[240], 15], [[274], 33], [[368], 80], [[448], 13], [[538], 42], [[561], 33], [[687], 11], [[775], 33], [[825], 25], [[834], 10], [[39], 48], [[120], 56], [[205], 28], [[401], 31], [[581], 28], [[704], 18], [[814], 19], [[35], 19], [[674], 24], [[733], 16], [[854], 36], [[950], 19], [[422], 11], [[449], 20], [[857], 10], [[895], 46], [[937], 45], [[964], 19], [[229], 20], [[283], 57], [[294], 12], [[352], 10], [[381], 31], [[708], 10], [[738], 26], [[766], 54], [[853], 19], [[883], 45], [[966], 36], [[978], 12], [[104], 10], [[143], 14], [[569], 38], [[620], 17], [[798], 34], [[214], 14], [[350], 32], [[529], 56], [[658], 22], [[682], 35], [[782], 37], [[809], 20], [[947], 28], [[970], 26], [[227], 16], [[390], 27], [[71], 49], [[192], 21], [[272], 11], [[279], 32], [[280], 21], [[496], 15], [[530], 12], [[597], 30], [[618], 10], [[675], 32], [[720], 40], [[914], 36], [[932], 19], [[183], 38], [[193], 12], [[217], 67], [[256], 13], [[276], 27], [[277], 10], [[653], 29], [[706], 17], [[878], 27], [[161], 24], [[175], 25], [[177], 60], [[424], 19], [[490], 10], [[571], 31], [[623], 24], [[795], 38], [[910], 16], [[960], 24], [[125], 16], [[130], 16], [[839], 11], [[392], 26], [[461], 15], [[801], 12], [[862], 40], [[27], 26], [[78], 23], [[921], 32], [[147], 20], [[411], 21], [[572], 19], [[579], 28], [[778], 35], [[803], 26], [[842], 10], [[903], 12], [[266], 16], [[290], 10], [[523], 27], [[614], 27], [[888], 30], [[944], 24], [[43], 23], [[70], 25], [[204], 34], [[334], 16], [[480], 28], [[874], 27], [[151], 32], [[504], 11], [[830], 13], [[890], 14], [[73], 20], [[118], 14], [[310], 20], [[419], 45], [[469], 10], [[484], 13], [[722], 43], [[810], 14], [[844], 33], [[846], 18], [[918], 22], [[967], 12], [[326], 17], [[403], 20], [[526], 25], [[774], 18], [[788], 31], [[789], 34], [[975], 13], [[116], 22], [[198], 18], [[201], 16], [[395], 16], [[171], 12], [[541], 32], [[701], 16], [[805], 16], [[946], 13], [[471], 14], [[487], 40], [[631], 24], [[638], 23], [[735], 16], [[780], 32], [[935], 20], [[17], 18], [[242], 14], [[758], 21], [[763], 15], [[956], 34], [[145], 49], [[385], 17], [[676], 24], [[731], 10], [[790], 12], [[792], 15], [[885], 32], [[522], 36], [[617], 26], [[12], 41], [[296], 27], [[354], 65], [[548], 19], [[684], 52], [[740], 14], [[841], 17], [[210], 17], [[346], 41], [[477], 21], [[605], 20], [[829], 57], [[884], 14], [[234], 10], [[355], 14], [[460], 53], [[649], 10], [[746], 18], [[600], 21], [[709], 11], [[28], 21], [[742], 12], [[5], 14], [[115], 16], [[517], 18], [[736], 14], [[744], 28], [[919], 34], [[196], 20], [[489], 26], [[494], 46], [[641], 10], [[673], 17], [[362], 47], [[591], 12], [[31], 24], [[58], 19], [[181], 12], [[329], 11], [[472], 25], [[573], 21], [[628], 15], [[651], 14], [[111], 11], [[154], 21], [[168], 20], [[580], 22], [[832], 29], [[871], 23], [[988], 15], [[72], 23], [[981], 15], [[10], 20], [[132], 29], [[172], 17], [[464], 13], [[21], 21], [[32], 38], [[54], 19], [[136], 13], [[239], 25], [[348], 21], [[100], 19], [[500], 12], [[48], 27], [[126], 12], [[319], 14], [[639], 15], [[765], 19], [[521], 19], [[112], 33], [[140], 27], [[285], 12], [[387], 14], [[594], 17], [[93], 23], [[583], 19], [[606], 14], [[236], 30], [[952], 16], [[90], 19], [[593], 29], [[122], 12], [[1], 13], [[423], 15], [[516], 24], [[6], 17], [[69], 21], [[415], 10], [[797], 20], [[913], 19], [[577], 19], [[110], 19], [[509], 35], [[611], 10], [[983], 10], [[995], 20], [[343], 12], [[527], 19], [[33], 24], [[158], 15], [[336], 11], [[989], 20], [[97], 12], [[793], 28], [[598], 34], [[427], 18], [[470], 40], [[37], 14], [[55], 20], [[95], 10], [[897], 19], [[275], 20], [[259], 10], [[45], 19], [[162], 20], [[378], 13], [[534], 17], [[711], 11], [[906], 20], [[912], 22], [[117], 12], [[373], 17], [[406], 10], [[546], 12], [[665], 15], [[963], 12], [[349], 26], [[8], 29], [[197], 11], [[413], 27], [[94], 14], [[982], 23], [[984], 16], [[515], 17], [[692], 49], [[694], 25], [[567], 12], [[57], 25], [[800], 12], [[812], 26], [[923], 17], [[160], 13], [[752], 40], [[852], 10], [[991], 10], [[998], 21], [[899], 15], [[595], 10], [[710], 13], [[867], 15], [[170], 12], [[438], 54], [[563], 10], [[357], 15], [[361], 10], [[322], 11], [[75], 30], [[108], 12], [[486], 13], [[440], 28], [[38], 20], [[252], 13], [[784], 10], [[265], 15], [[686], 13], [[468], 11], [[819], 12], [[886], 30], [[429], 10], [[843], 13], [[129], 17], [[510], 30], [[241], 11], [[68], 14], [[860], 13], [[318], 11], [[887], 17], [[309], 11], [[804], 19], [[826], 31], [[394], 13], [[707], 15], [[838], 14], [[815], 11], [[948], 13], [[308], 12], [[661], 33], [[634], 23], [[215], 12], [[351], 13], [[405], 16], [[949], 13], [[893], 20], [[922], 14], [[173], 14], [[258], 13], [[450], 17], [[428], 13], [[550], 10], [[769], 15], [[732], 10], [[820], 11], [[207], 11]], [[[368, 937], 10], [[368, 529], 10], [[368, 829], 12], [[368, 438], 10], [[538, 878], 11], [[283, 515], 13], [[569, 801], 10], [[569, 862], 11], [[529, 782], 12], [[529, 598], 12], [[720, 780], 10], [[217, 283], 14], [[217, 487], 11], [[217, 346], 23], [[217, 515], 14], [[217, 394], 10], [[217, 661], 10], [[177, 310], 10], [[571, 853], 10], [[571, 623], 10], [[571, 795], 10], [[392, 801], 11], [[392, 862], 15], [[461, 862], 10], [[801, 862], 12], [[27, 357], 10], [[480, 752], 10], [[789, 829], 15], [[354, 583], 10], [[354, 357], 10], [[346, 515], 13], [[460, 684], 10], [[58, 354], 14], [[58, 357], 10], [[33, 283], 13], [[33, 217], 13], [[33, 346], 13], [[33, 515], 12], [[158, 583], 11], [[598, 782], 10], [[470, 534], 11], [[75, 684], 12], [[75, 438], 12]], [[[529, 598, 782], 10], [[217, 346, 515], 13], [[392, 801, 862], 11], [[33, 346, 515], 12]]]\n"
     ]
    }
   ],
   "source": [
    "def getAllItems(baskets):\n",
    "    docAllItems = list()\n",
    "    for basket in baskets:\n",
    "        docAllItems.extend(basket)\n",
    "    return Counter(docAllItems)\n",
    "\n",
    "def getFirstStage(preDictionary, t=12):\n",
    "    perStageSets = list()\n",
    "    frequencyMap = list()\n",
    "    for key in preDictionary.keys():\n",
    "        if int(preDictionary[key]) >= t :\n",
    "            if type(key) == int:\n",
    "                perStageSets.append([key])\n",
    "                frequencyMap.append([[key], preDictionary[key]])\n",
    "\n",
    "            else:\n",
    "                perStageSets.append(key.sort())\n",
    "    return perStageSets, frequencyMap\n",
    "\n",
    "def getRelevantItems(itemsCount, t=12):\n",
    "    perStageSets = list()\n",
    "    frequencyMap = list()\n",
    "    for item in itemsCount:\n",
    "        if item[-1] >= t :\n",
    "            perStageSets.append(item[0])\n",
    "            frequencyMap.append(item)\n",
    "    return perStageSets, frequencyMap\n",
    "\n",
    "def createItems(preStageSets, docAllItems):\n",
    "    nextStageLists = list()\n",
    "    for preStageSet in preStageSets:\n",
    "        for key in docAllItems:\n",
    "            if preStageSet[-1] < key[0]:\n",
    "                nextStageLists.append(preStageSet + key)\n",
    "    return nextStageLists\n",
    "\n",
    "def getItemsCount(baskets, stageLists):\n",
    "    allStageItem = list()\n",
    "    relevantItemList = list()\n",
    "    for backet in baskets:\n",
    "        for index, item in enumerate(stageLists):\n",
    "            if list(set(backet) & set(item)) == item:\n",
    "                allStageItem.append(index)\n",
    "    firstCounter = Counter(allStageItem)\n",
    "    for index, item in enumerate(stageLists):\n",
    "        for key in firstCounter.keys():\n",
    "            if index == key :\n",
    "                relevantItemList.append([item, firstCounter[key]])\n",
    "\n",
    "    return relevantItemList\n",
    "\n",
    "def apriori(baskets, t):\n",
    "    frequencyMap = list()\n",
    "    aprioriResult = list()\n",
    "    preDic = getAllItems(baskets)\n",
    "    \n",
    "    DicItems, frequencyMaptmp = getFirstStage(preDic, t)\n",
    "    stageItems, frequencyMaptmp = getFirstStage(preDic, t)\n",
    "    while stageItems != []:\n",
    "        aprioriResult.append(stageItems)\n",
    "        frequencyMap.append(frequencyMaptmp)\n",
    "\n",
    "        tmp = createItems(stageItems, DicItems)\n",
    "        tmp = getItemsCount(baskets, tmp)\n",
    "        stageItems,frequencyMaptmp = getRelevantItems(tmp, t)\n",
    "\n",
    "    return aprioriResult, frequencyMap\n",
    "\n",
    "    \n",
    "\n",
    "basketstmp = baskets[0:1000]\n",
    "aprioriResult, frequencyMap = apriori(basketstmp, 10)\n",
    "print(frequencyMap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Association results\n",
    "Develop and implement an algorithm for generating association rules between frequent itemsets discovered using the A-Priori algorithm in a dataset of sales transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[283] -------> 515 :  0.7647058823529411\n",
      "[569] -------> 801 :  0.8333333333333334\n",
      "[217] -------> 515 :  0.8235294117647058\n",
      "[217] -------> 394 :  0.7692307692307693\n",
      "[392] -------> 801 :  0.9166666666666666\n",
      "[862] -------> 801 :  1.0\n",
      "[346] -------> 515 :  0.7647058823529411\n",
      "[354] -------> 58 :  0.7368421052631579\n",
      "[33] -------> 515 :  0.7058823529411765\n",
      "[583] -------> 158 :  0.7333333333333333\n",
      "[217, 346] -------> 515 :  0.7647058823529411\n",
      "[392, 862] -------> 801 :  0.9166666666666666\n",
      "[33, 346] -------> 515 :  0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "def getAssociationRules(basketstmp, confidence=0.7, support=10):\n",
    "    aprioriResult, frequencyMap = apriori(basketstmp, support)\n",
    "    assuciationResult = list()\n",
    "    for itemList in aprioriResult:\n",
    "        if len(itemList[0]) == 1: continue\n",
    "        for item in itemList:\n",
    "            for num in item:\n",
    "                itemtmp = list(item)\n",
    "                itemtmp.remove(num)\n",
    "                for i in frequencyMap[0]:\n",
    "                    if set(set(i[0]) & set([num])) == set([num]):\n",
    "                        numSupport = i[-1]\n",
    "                        #print(numSupport)\n",
    "                for j in frequencyMap[len(item)-1]:\n",
    "                    if set(set(j[0]) & set(item)) == set(item):\n",
    "                        itemSupport = j[-1]\n",
    "                        #print(itemSupport)\n",
    "                perConfidence = itemSupport/numSupport\n",
    "                #print(perConfidence)\n",
    "                if (perConfidence >= confidence):\n",
    "                    assuciationResult.append([itemtmp,num,perConfidence])\n",
    "                    print(itemtmp, '------->', num, ': ', perConfidence)\n",
    "    return assuciationResult\n",
    "\n",
    "associationResult = getAssociationRules(aprioriResult, frequencyMap)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
