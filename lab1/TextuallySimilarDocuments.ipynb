{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1: Finding Similar Items: Textually Similar Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "You are to implement the stages of finding textually similar documents based on Jaccard similarity using the shingling, minhashing, and locality-sensitive hashing (LSH) techniques and corresponding algorithms. The implementation can be done using any big data processing framework, such as Apache Spark, Apache Flink, or no framework, e.g., in Java, Python, etc. To test and evaluate your implementation, write a program that uses your implementation to find similar documents in a corpus of 5-10 or more documents, such as web pages or emails.\n",
    "\n",
    "The stages should be implemented as a collection of classes, modules, functions, or procedures depending on the framework and the language of your choice. Below, we describe sample classes implementing different stages of finding textually similar documents. You do not have to develop the exact same classes and data types described below. Feel free to use data structures that suit you best.\n",
    "\n",
    "* A class Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, computes a hash value for each unique shingle and represents the document in the form of an ordered set of its hashed k-shingles.\n",
    "* A class CompareSets computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "* A class MinHashing that builds a minHash signature (in the form of a vector or a set) of a given length n from a given set of integers (a set of hashed shingles).\n",
    "* A class CompareSignatures estimates the similarity of two integer vectors – minhash signatures – as a fraction of components in which they agree.\n",
    "(Optional task for extra 2 bonus points) A class LSH that implements the LSH technique: given a collection of minhash signatures (integer vectors) and a similarity threshold t, the LSH class (using banding and hashing) finds candidate pairs of signatures agreeing on at least a fraction t of their components.\n",
    "To test and evaluate your implementation's scalability (the execution time versus the size of the input dataset), write a program that uses your classes to find similar documents in a corpus of 5-10 documents. Choose a similarity threshold s (e.g., 0,8) that states that two documents are similar if the Jaccard similarity of their shingle sets is at least s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Introduction\n",
    "I extracted five emails to form test data for our program. I create all of the methods mentioned above as functions below. For the report, I have explained each algorithm in the beginning of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libararies\n",
    "\n",
    "Here are some libraries that I used in the program.\n",
    "* Using \"numpy\" as our data format. \n",
    "* Using \"itertools\" for iteration in the function \"LSH\".\n",
    "* Using \"collections\" to computes and merges the same elements in one list in the function \"LSH\".\n",
    "* Using \"time\" to collect program run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shingling\n",
    "Shingling is used to transform document into a set that contains tokens in the document.\n",
    "For example, a document \"using numpy\" will be divide into tokens {us si in ng gn .. py} with k-shingling size of 2\n",
    "\n",
    "Function \"shingling\" in our program will first replace all the spaces and then divide the document into tokens by given value k. \n",
    "\n",
    "Function \"shinglingHash\" transform sets that created from shingling into hash by using naive hash function in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ju', 'es', 'at', 'ta', 'us', 'te', 'st'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{452711271,\n",
       " 1070399262,\n",
       " 1665777727,\n",
       " 1791901764,\n",
       " 3191421644,\n",
       " 3496112872,\n",
       " 3654990473}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shingling(doc, k):\n",
    "    doc = doc.replace(\" \",\"\")\n",
    "    docLength = len(doc)\n",
    "    shingles = {doc[i:i + k] for i in range(docLength - k + 1)}\n",
    "    return shingles\n",
    "\n",
    "def shinglingHash(doc, k):\n",
    "    shingles = shingling(doc, k)\n",
    "    hashBoundary=((2**32)-1)\n",
    "    hashes = {hash(i)%hashBoundary for i in shingles}\n",
    "    return hashes\n",
    "\n",
    "print(shingling(\"just a test\", 2))\n",
    "shinglingHash(\"just a test\", 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard similarity \n",
    "\n",
    "The Jaccard similarity of two sets, C1 and C2, is the fraction of \n",
    "common items, i.e., the fraction of their intersection – size of their \n",
    "intersection divided by the size of their union:\n",
    "sim(C1, C2) = |C1⋂C2| / |C1⋃C2|\n",
    "\n",
    "In the program, I use function \"intersection\" and \"union\" to get the results of Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3654990473, 2421983502, 1070399262, 1558407970, 769771179, 1665777727, 1791901764, 3191421644, 1711452243, 1237569632, 2916862821, 3500351206, 452711271, 3496112872, 38192361, 4085570544, 645652722, 2144157042, 234110072}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48148148148148145"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compareSets(doc1, doc2):\n",
    "    intersection = len(doc1.intersection(doc2))\n",
    "    union = len(doc1.union(doc2))\n",
    "    return intersection/union\n",
    "\n",
    "\n",
    "doc1 = shinglingHash(\"I'm okey, it's just a test\", 2)\n",
    "doc2 = shinglingHash(\"Are you okey, it's not a test\", 2)\n",
    "\n",
    "print(doc1)\n",
    "compareSets(doc1, doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-hash\n",
    "Then follow the homework discription, I implement the MinHashing algorithm. I have made a minHashing function that takes a set of shingles and returns a signature. Details of our implementation:\n",
    "\n",
    "* First, create original chart (the chart that formed through shingling set that with 0 and 1).\n",
    "* Second, create a random vector for original chart to transform to a min-hash chart.\n",
    "* Third, find that first col that contains 1 to form a signature chart.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [2 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 2]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 3]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 2]\n",
      " [2 0]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [1 0]\n",
      " [0 2]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]]\n",
      "0.47\n"
     ]
    }
   ],
   "source": [
    "def minHashing(shinglingList, K=100):\n",
    "    union = set()\n",
    "    # for shingling in shinglingList:\n",
    "    #   union.union(shingling)\n",
    "    union = set().union(*shinglingList)\n",
    "    oriChart = np.array([[int(e in s) for s in shinglingList] for e in union])\n",
    "    sigChart = []\n",
    "    for i in range(K):\n",
    "      randomSet = np.random.RandomState(seed=i).permutation(oriChart.shape[0])\n",
    "      perSigChart = np.take(oriChart, randomSet,axis=0)\n",
    "      sigCharRow = []\n",
    "      for col in perSigChart.T:\n",
    "        sigCharRow.append([np.where(col == 1)][0][0][0])\n",
    "      sigChart.append(sigCharRow)\n",
    "    return np.array(sigChart)\n",
    "\n",
    "def compareSignatures(sigChart):\n",
    "  return (np.sum(sigChart[:,0] == sigChart[:,1])) / len(sigChart[:,0])\n",
    "\n",
    "testminHashing = minHashing([doc1, doc2])\n",
    "print(testminHashing)\n",
    "print(compareSignatures(testminHashing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another min-hash function is to finds the signature matrix without constructing the characteristic matrix, but use a hash function on the form of $ax + b mod N$.\n",
    "\n",
    "To compare min-hash results ,function \"compareHashSets\" estimates the similarity of two integer vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.35178300e+06 1.59259731e+08 1.34933799e+08 4.10128996e+08\n",
      "  1.42226736e+08 3.25538366e+08 3.74523254e+08 2.17887700e+07\n",
      "  5.04125380e+07 5.55232479e+08 5.27062200e+06 1.12472500e+06\n",
      "  4.41712986e+08 8.63069658e+08 3.84970300e+07 2.26157102e+08\n",
      "  3.10759117e+08 1.30022943e+08 1.84466459e+08 1.94876024e+08\n",
      "  6.20451770e+07 6.40417135e+08 1.03082552e+08 6.88109252e+08\n",
      "  4.78131967e+08 1.39912656e+08 1.36770146e+08 1.72775804e+08\n",
      "  5.17270804e+08 2.46990300e+07 7.91173962e+08 2.48979347e+08\n",
      "  9.16391700e+06 2.99004801e+08 5.68057900e+06 1.08943247e+08\n",
      "  1.30512205e+08 2.40963100e+07 2.01449450e+07 6.46345110e+07\n",
      "  6.48986795e+08 8.56120240e+07 3.80111149e+08 2.54544362e+08\n",
      "  3.93920177e+08 2.70735910e+07 1.74197331e+08 2.99918197e+08\n",
      "  4.49622137e+08 1.77615295e+08 1.56119444e+08 1.29113500e+06\n",
      "  1.84237280e+07 1.09266555e+08 1.77714339e+08 2.43794167e+08\n",
      "  2.55352077e+08 4.34992244e+08 4.20050655e+08 3.34379782e+08\n",
      "  7.83623560e+07 9.74568520e+07 1.50949110e+08 1.90106659e+08\n",
      "  1.67672303e+08 1.00154973e+08 2.98889051e+08 1.19564550e+08\n",
      "  3.67331540e+07 8.43808200e+06 9.53452012e+08 1.46044890e+07\n",
      "  2.30425929e+08 7.26164200e+06 1.92115887e+08 2.31302774e+08\n",
      "  3.12789928e+08 1.43205763e+08 7.42219170e+07 5.58929000e+06\n",
      "  6.85837742e+08 1.23138840e+07 3.82473670e+07 1.94596150e+07\n",
      "  2.49180770e+08 2.05766027e+08 5.78646110e+07 3.60213982e+08\n",
      "  4.53457707e+08 1.85899446e+08 2.47062340e+07 1.52768390e+07\n",
      "  2.44518589e+08 4.06071736e+08 7.22415000e+06 1.79132373e+08\n",
      "  2.62570580e+07 9.49398770e+07 2.20084746e+08 2.43113846e+08]\n",
      " [7.35178300e+06 4.66944414e+08 5.61989516e+08 3.66195556e+08\n",
      "  1.72722875e+08 3.25538366e+08 3.39325599e+08 2.17887700e+07\n",
      "  5.04125380e+07 4.08242910e+07 5.68615260e+07 1.12472500e+06\n",
      "  3.14565260e+07 1.71307816e+08 3.84970300e+07 3.75716955e+08\n",
      "  3.10759117e+08 1.30022943e+08 2.38114940e+07 1.94876024e+08\n",
      "  2.38847027e+08 3.80472610e+07 4.98204056e+08 8.22778720e+07\n",
      "  5.06501656e+08 3.72429582e+08 1.38788436e+08 1.17179039e+08\n",
      "  3.20991551e+08 2.46990300e+07 3.02395332e+08 2.48979347e+08\n",
      "  9.16391700e+06 9.31880730e+07 5.68057900e+06 1.24690121e+08\n",
      "  5.52797820e+07 1.31953316e+08 2.01449450e+07 2.62826070e+08\n",
      "  1.96196786e+08 9.70686220e+07 4.42002679e+08 6.26114672e+08\n",
      "  3.93920177e+08 7.79052100e+06 1.74197331e+08 2.99918197e+08\n",
      "  5.86431500e+06 1.77615295e+08 1.56119444e+08 1.95416117e+08\n",
      "  1.84237280e+07 1.09266555e+08 3.20376801e+08 3.72291161e+08\n",
      "  4.75269810e+07 5.52552530e+07 1.80003602e+08 3.34379782e+08\n",
      "  7.83623560e+07 9.74568520e+07 1.50949110e+08 1.90106659e+08\n",
      "  1.71428223e+08 1.64145948e+08 8.15202579e+08 1.01827379e+08\n",
      "  5.95150610e+07 2.39281199e+08 9.53452012e+08 1.46044890e+07\n",
      "  1.00134503e+09 1.16093710e+07 4.98081310e+07 3.62298785e+08\n",
      "  3.12789928e+08 1.43205763e+08 7.42219170e+07 5.58929000e+06\n",
      "  9.14226960e+07 9.21922720e+07 3.82473670e+07 1.94596150e+07\n",
      "  6.25317750e+07 2.05766027e+08 1.53472544e+08 3.60213982e+08\n",
      "  4.53457707e+08 1.85899446e+08 5.98811890e+07 9.29149530e+07\n",
      "  8.08636580e+07 1.63801423e+08 8.37792840e+07 1.79132373e+08\n",
      "  9.80912810e+07 9.49398770e+07 5.40690200e+07 7.88166280e+07]]\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "def minHashingwithHash(shinglingList, K=100):\n",
    "    maxID = (2**31)-1\n",
    "    c = (2**32)-1 \n",
    "    a = np.random.RandomState(seed=1).randint(low=0, high=maxID, size=K, dtype=np.int64)\n",
    "    b = np.random.RandomState(seed=2).randint(low=0, high=maxID, size=K, dtype=np.int64)\n",
    "    sigHashChart = []\n",
    "    for i in range(K):\n",
    "        perSigHashChart = []\n",
    "        for j in shinglingList:\n",
    "            perSigHashChart = np.hstack((perSigHashChart,np.min([(a[i] * e + b[i]) % c for e in j])))\n",
    "        sigHashChart.append(perSigHashChart)\n",
    "        \n",
    "    return np.array(sigHashChart)\n",
    "\n",
    "def compareHashSets(document1, document2):\n",
    "    return (np.sum(document1 == document2)) / len(document1)\n",
    "\n",
    "testminHashingWithHash = minHashingwithHash([doc1, doc2])\n",
    "print(testminHashingWithHash.T)\n",
    "print(compareHashSets(testminHashingWithHash[:,0],testminHashingWithHash[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locality-Sensitive Hashing\n",
    "\n",
    "A class LSH that implements the LSH technique: given a collection of minhash signatures (integer vectors) and a similarity threshold t, the LSH class (using banding and hashing) finds candidate pairs of signatures agreeing on at least a fraction t of their components. Detail of our implementation:\n",
    "\n",
    "* Develop an emty sets for buckets.\n",
    "* Add index into buckets after hashing with a group of signature.\n",
    "* For each buckets, if it has more than one index in, are added into relevent buckets.\n",
    "* Choose the index group that has the value bigger then threshold to add into results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', '1')]\n"
     ]
    }
   ],
   "source": [
    "def lhs(signatures, t, bandsNum = 5, bucketsNum = 5):\n",
    "    \n",
    "    buckets = [set() for x in range(0, bucketsNum)]\n",
    "    bandsTmp = np.linspace(0, len(signatures[0]), bandsNum)\n",
    "    bands = bandsTmp.astype(int).tolist()\n",
    "\n",
    "    for index, signature in enumerate(signatures):\n",
    "        for i in range(0, bandsNum - 1):\n",
    "            band = \"\".join(str(x) for x in signature[bands[i]:bands[i + 1]])\n",
    "            bucket = hash(band) % bucketsNum\n",
    "            buckets[bucket].add(\"%s\" % index)\n",
    "\n",
    "    relevant_buckets = list()\n",
    "    for x in buckets:\n",
    "        if len(x) >= 2:\n",
    "            relevant_buckets.append(x)\n",
    "    \n",
    "    relevant_pairs = list()\n",
    "    for bucket in relevant_buckets:\n",
    "        pairs = list()\n",
    "        for x in itertools.combinations(bucket, 2):\n",
    "            if x[0] != x[1]:\n",
    "                pairs.append(x)\n",
    "        relevant_pairs += pairs\n",
    "\n",
    "    count = Counter(relevant_pairs)\n",
    "\n",
    "    indices = list()\n",
    "    for index, x in enumerate(count.values()):\n",
    "        if (x/(bandsNum-1)) >= t:\n",
    "            indices.append(index)\n",
    "\n",
    "    candidate_pairs = list()\n",
    "    for index, pair in enumerate(count.keys()):\n",
    "        if index in indices:\n",
    "            candidate_pairs.append(pair)\n",
    "\n",
    "    return candidate_pairs\n",
    "\n",
    "print(lhs(testminHashingWithHash.T, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "I extract five emails as our data to test these functions.\n",
    "\n",
    "* Using shinging function to create sets of these documents. Then compare these shingling sets with function compareSets.\n",
    "* Using minHash function to form a signature sets. Get the results using compareMinHashsets.\n",
    "* Compare the time cost by using shingling with using min-hash.\n",
    "* Using LSH to get reletive doc with different threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-2 0.5620767494356659\n",
      "1-3 0.291005291005291\n",
      "1-4 0.3339920948616601\n",
      "1-5 0.2793522267206478\n",
      "2-3 0.2813688212927757\n",
      "2-4 0.30168776371308015\n",
      "2-5 0.25877192982456143\n",
      "3-4 0.3630705394190871\n",
      "3-5 0.31759656652360513\n",
      "4-5 0.36855036855036855\n",
      "0.57\n",
      "0.28\n",
      "without min-hash: 0.003000974655151367 seconds\n",
      "with min-hash: 0.0009980201721191406 seconds\n",
      "[]\n",
      "[('3', '0'), ('3', '1'), ('0', '1')]\n",
      "[('3', '0'), ('3', '1'), ('0', '1'), ('4', '2')]\n"
     ]
    }
   ],
   "source": [
    "docList = list()\n",
    "for i in range(1,6):\n",
    "    docNum = (\"%s\" % i)\n",
    "    docName = \"doc\" + docNum + \".txt\"\n",
    "    with open(docName, \"r\") as f:\n",
    "        docList.append(f.read())\n",
    "    f.close\n",
    "\n",
    "docListShingling = list()\n",
    "for i in range(5):\n",
    "    docListShingling.append(shinglingHash(docList[i],2))\n",
    "\n",
    "print('1-2', compareSets(docListShingling[0],docListShingling[1]))\n",
    "print('1-3', compareSets(docListShingling[0],docListShingling[2]))\n",
    "print('1-4', compareSets(docListShingling[0],docListShingling[3]))\n",
    "print('1-5', compareSets(docListShingling[0],docListShingling[4]))\n",
    "print('2-3', compareSets(docListShingling[1],docListShingling[2]))\n",
    "print('2-4', compareSets(docListShingling[1],docListShingling[3]))\n",
    "print('2-5', compareSets(docListShingling[1],docListShingling[4]))\n",
    "print('3-4', compareSets(docListShingling[2],docListShingling[3]))\n",
    "print('3-5', compareSets(docListShingling[2],docListShingling[4]))\n",
    "print('4-5', compareSets(docListShingling[3],docListShingling[4]))\n",
    "\n",
    "docMinHash = minHashingwithHash(docListShingling)\n",
    "print(compareHashSets(docMinHash[:,0],docMinHash[:,1]))\n",
    "print(compareHashSets(docMinHash[:,2],docMinHash[:,4]))\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    compareSets(docListShingling[0],docListShingling[1])\n",
    "print(\"without min-hash: %s seconds\" % (time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    compareHashSets(docMinHash[:,0],docMinHash[:,1])\n",
    "print(\"with min-hash: %s seconds\" % (time.time() - start))\n",
    "\n",
    "print(lhs(docMinHash.T, 0.8))\n",
    "print(lhs(docMinHash.T, 0.6))\n",
    "print(lhs(docMinHash.T, 0.4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of the Testing Result\n",
    "\n",
    "* By using the funcition shingling, program can extract tokens from each doc for further action (comprare). And the comparation results that created by using these tokens are close to the real similirity relations between these five emails.\n",
    "\n",
    "* The comparation of using min-hash function is close to the result of comparation by shingling as you can see on the top. At the same time, the time cost in min-hash function is less than only use shingling.\n",
    "\n",
    "* By using different value of threshold t, the result of finding relevent doc by using LHS function is showing on the top. We can see that with the threshold value getting bigger, the relative doc getting fewer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
